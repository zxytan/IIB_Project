{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 09/10/20\n",
    "Post-vacation contact with supervisor - added to Slack and given paper on Bayesian Machine learning in metamaterial design to read (https://onlinelibrary-wiley-com.ezp.lib.cam.ac.uk/doi/full/10.1002/adma.201904845#adma201904845-fig-0002)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11/10/20\n",
    "Testing GPyOpt functionality with their manual examples and functions from https://en.wikipedia.org/wiki/Test_functions_for_optimization. 1D and 2D straightforward with visuals. Tried with higher dimensional problems (n>=10) - sphere function was fine, but less optimal when the function is rough and needs more iterations (local minima)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12/10/20\n",
    "Formalise testing - see gpyopt_test.py\n",
    "Added timing - 15 iterations for 2D Booth function and 10D sphere function both took around 5s to run, 40 iterations for 10D Rastrigin function took 13s with f(x) error of 0.8. Not bad!\n",
    "Made github repo for project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13/10/20\n",
    "Call with supervisor to outline next steps:\n",
    "* Further testing with GPyOpt\n",
    "    * evaluation time, no. of evaluations to optimum\n",
    "    * compare different acquisition functions\n",
    "    * test with non-linear functions (introduce discontinuities)\n",
    "    * sparse Gaussian processes to lower compute time\n",
    "* Consider multi-fidelity Gaussian processes - data from multiple sources\n",
    "* Look into deep learning methods for optimisation - fast.ai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 25/10/20\n",
    "Acquisition function $$u(x)$$ guides finding new samples in objective function. Balance exploration (samples from unexplored/high uncertainty areas) and exploitation (samples around current optimum, drill down to true (local) optimum). Formally, take sample where $$\\mathbf{x}=\\underset{\\mathbf{x}}{\\arg \\max} u(x|\\mathcal{D}_{1:t-1})$$ where $$\\mathcal{D}_{1:t-1}$$ is data up to this point. Most common acquisition functions are Maximum Probability of Improvement (MPI), Expected Improvement (EI) and Upper Confidence Bound (UCB).\n",
    "\n",
    "Testing of GPyOpt - evaluation time and accuracy when varying noise, maximum iterations, acquisition function, dimension, function type (convex?). Results given in gpyopt_test_results.xlsx\n",
    "\n",
    "Biggest factors in accuracy loss, ceteris paribus:\n",
    "* roughness of function, gets stuck in local minima for a long time\n",
    "* number of dimensions/parameters, high dimensional inputs take longer to calculate/train to good accuracy\n",
    "\n",
    "Still to do: \n",
    "* testing with non-linear functions\n",
    "* investigate sparse GP (can test very easily but what is it doing differently behind the scenes?)\n",
    "* set up multi-fidelity GP\n",
    "\n",
    "Can parallelise optimisation - biggest bottleneck in evaluating objective function (according to GPyOpt documention). This needs further investigation to find where it can actually help, especially in reference to batches.\n",
    "\n",
    "Spoke to Tianyi (PhD student) about her finite element model code in C++. Will have this resource to output results but will need integrating into Python. Consider adapting code/look into existing Python libraries (e.g. SfePy).\n",
    "\n",
    "Thoughts on presentation outline: \n",
    "* introduce and walk through Gaussian Processes for 1D/2D\n",
    "* give example where optimization might be useful (minimise weight for a component while keeping strength above certain threshold)\n",
    "* connect GP with structures\n",
    "* pros and cons\n",
    "\n",
    "Report can probably also follow this general outline, with more specific examples and experiments to show optimisation in practice for simple and complex structures. Aim to have end result of a useable modular code base that can be used to perform GP optimisation on any defined structure problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 26/10/20\n",
    "Action points coming out of call with supervisor:\n",
    "* use relative errors\n",
    "* does optimisation slow with number of iterations? (should do from covariance matrix getting larger and harder to invert)\n",
    "* test sparse GP as way to combat costly computations\n",
    "* look into python FEM libraries\n",
    "* start thinking about structural problems to centre final experimentation around\n",
    "* test multi-fidelity GP\n",
    "\n",
    "Make sure to keep bank of images/graphs to put in report, systematically go through interest points and build up story."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01/11/20\n",
    "Relative error wrt true **X** not possible when true **X** is 0. Similar for f(**X**). (For real structural optimisation problems this is unlikely to be a problem.) 2 options:\n",
    "* Measure relative error percentage wrt benchmark error - GP model always imperfect, what can we accept as \"expected error\"? \n",
    "* Add constant component to true function to work around minimum f(**X**)=0 problem.\n",
    "\n",
    "First option encodes error tolerance, which is useful for real problems. Optimising certain variables accurately has smaller influence on the final result than other variables. To measure relative error fairly, this benchmark error should change with complexity of problem. We can also choose benchmark error as the average error.\n",
    "\n",
    "Second option is an easy work-around which does not require us to choose a benchmark error. However the added constant component would be arbitrary and not add information, just a way to turn errors into percentage errors.\n",
    "\n",
    "Performed additional testing with sphere and rastrigin functions at 10-D. Fixing everything else, I varied the number of iterations and recorded the time taken per iteration. I repeated this for 5 rounds and plotted the averages. From the graph in Sheet 6 of gpyopt_test_results.xlsx, can see that it is obvious for the sphere function that optimisation slows with the number of iterations. However, this is not as clear for the rastrigin function - there is still a vague trend showing the optimisation shows, but the graph is much more level. Not sure why this is? **something to look into\n",
    "\n",
    "Sparse GP supposed to speed up process of inverting covariance matrix but not seeing this, in fact seeing a significant slow down in time taken to run a fixed number of iterations. Why is this?\n",
    "\n",
    "SfePy can be used but need to figure out how to generate new meshes - ask supervisor about this. Everything specified in problem description file and solved with one command (easy to use but hard to debug)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03/11/20\n",
    "Sparse GP issue was coding bug, now seeing speed up from using sparseGP model. Seems to be useful for fitting to lots of data points but not for doing optimization where it uses acquisition function to find new points. Why? 2866s to optimise with 10,000 data points (2D) with sparseGP, several hours and still not complete for GP.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04/11/20\n",
    "Action points out of meeting with supervisor:\n",
    "* look at GPy to check what sparse GP model is doing\n",
    "* look into PyNite for FEM (https://github.com/JWock82/PyNite)\n",
    "* test with constrained functions (constrain volume of materials etc)\n",
    "* do first draft of presentation for next week"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12/11/20\n",
    "First draft of presentation completed. Sent to supervisor for content check, aim to run through at next meeting before presentation day (26/11/20).\n",
    "sparseGP model needs inducing samples that are drawn from X and Y inputs to BayesianOptimisation function, so cannot be run just using acquisition function. Idea is to summarise large amount of data using a small numer of pseudo-data (e.g. highlight peaks and valleys). Uses Variational Free Energy model - approximation of posterior distribution, minimising KL divergence between the 2 functions. Need to dig into this more.\n",
    "(References for later: \n",
    "* https://towardsdatascience.com/sparse-and-variational-gaussian-process-what-to-do-when-data-is-large-2d3959f430e7\n",
    "* http://proceedings.mlr.press/v5/titsias09a/titsias09a.pdf\n",
    "* https://www.youtube.com/watch?v=sQmsQq_Jfi8\n",
    "* http://gpss.cc/gpss17/slides/gp-approx-new.pdf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
